{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05b6a97e",
   "metadata": {},
   "source": [
    "# CS336 Assignment 1 (basics): Building a Transformer LM\n",
    "# 1 作业概述\n",
    "从零开始构建训练一个标准 Transformer 语言模型（LM）所需的所有组件，并训练一些模型。  \n",
    "\n",
    "## 你将实现\n",
    "1. 字节对编码（BPE）分词器\n",
    "2. Transformer 语言模型\n",
    "3. 交叉熵损失函数和 AdamW 优化器\n",
    "4. 支持模型与优化器状态序列化与加载的训练循环\n",
    "\n",
    "## 你将运行\n",
    "1. 在 TinyStories 数据集上训练一个 BPE 分词器。  \n",
    "2. 用训练好的分词器将数据集转换为整数 ID 序列。  \n",
    "3. 在 TinyStories 数据集上训练一个 Transformer 语言模型。  \n",
    "4. 使用训练好的 Transformer LM 生成样本并评估困惑度（perplexity）。  \n",
    "5. 在 OpenWebText 数据集上训练模型，并将你得到的困惑度提交到排行榜。  \n",
    "\n",
    "## 你可以使用的工具\n",
    "我们希望你从零实现这些组件。特别是，你不能使用 `torch.nn`、`torch.nn.functional` 或 `torch.optim` 中的任何定义，除了以下内容：  \n",
    "- `torch.nn.Parameter`  \n",
    "- `torch.nn` 中的容器类（如 `Module`、`ModuleList`、`Sequential` 等）  \n",
    "- `torch.optim.Optimizer` 基类  \n",
    "\n",
    "你可以使用 PyTorch 的其他定义。如果不确定某个函数或类是否允许使用，可以在 Slack 上询问。遇到不确定时，请考虑使用它是否会破坏“从零开始”的作业理念。  \n",
    "\n",
    "## 关于 AI 工具的声明\n",
    "允许使用大型语言模型（如 ChatGPT）来回答低层次的编程问题或关于语言模型的高层次概念问题，但禁止直接用它来解决作业中的问题。  我们强烈建议你在完成作业时禁用 IDE 中的 AI 自动补全（如 Cursor Tab、GitHub Copilot），但允许使用非 AI 自动补全（例如函数名自动补全）。我们发现 AI 自动补全会使你更难深入理解作业内容。  \n",
    "\n",
    "## 代码结构\n",
    "所有作业代码和作业说明都在 GitHub 仓库中：  \n",
    "[github.com/stanford-cs336/assignment1-basics](https://github.com/stanford-cs336/assignment1-basics)  \n",
    "\n",
    "请 `git clone` 该仓库，如果有更新，我们会通知你 `git pull` 获取最新版本。  \n",
    "\n",
    "1. `cs336_basics/*`：你将编写代码的地方。注意，这里没有预先写好的代码，你可以完全从零开始。  \n",
    "2. `adapters.py`：你的代码必须提供一组功能。对于每个功能（如缩放点积注意力），在 `adapters.py` 中的实现函数（如 `run_scaled_dot_product_attention`）里调用你写的代码即可。**注意**：你对 `adapters.py` 的修改不应包含实质性逻辑，它只是胶水代码。  \n",
    "3. `test_*.py`：包含你必须通过的测试（如 `test_scaled_dot_product_attention`），这些测试会调用 `adapters.py` 中的钩子。**不要修改测试文件**。  \n",
    "\n",
    "## 提交方式\n",
    "你需要向 Gradescope 提交以下文件：  \n",
    "- `writeup.pdf`：回答所有书面问题，请用排版工具（如 LaTeX）编写。  \n",
    "- `code.zip`：包含你编写的所有代码。  \n",
    "\n",
    "要提交到排行榜，请向以下仓库提交 Pull Request：  \n",
    "[github.com/stanford-cs336/assignment1-basics-leaderboard](https://github.com/stanford-cs336/assignment1-basics-leaderboard)  \n",
    "排行榜提交的详细说明请参考仓库中的 `README.md`。  \n",
    "\n",
    "## 数据集来源\n",
    "本次作业将使用两个预处理好的数据集：  \n",
    "- TinyStories（Eldan 和 Li，2023）  \n",
    "- OpenWebText（Gokaslan 等人，2019）  \n",
    "\n",
    "两个数据集都是单个的大型纯文本文件。  如果你是在课程中做作业，可以在任何非 head 节点机器的 `/data` 目录找到它们。如果你是在家跟做，可以用 `README.md` 中的命令下载它们。  \n",
    "\n",
    "---\n",
    "\n",
    "### 低资源/降规模提示（Init）\n",
    "在整个课程作业讲义中，我们会给出一些提示，帮助你在缺少 GPU 资源或没有 GPU 资源的情况下完成作业。例如，有时会建议缩小数据集或模型规模，或者解释如何在 MacOS 集成 GPU 或 CPU 上运行训练代码。  \n",
    "这些“低资源提示”会用蓝色方框标出。即使你是注册的斯坦福学生并有课程机器的访问权限，阅读这些提示也能帮助你更快迭代、节省时间。  \n",
    "\n",
    "---\n",
    "\n",
    "### 低资源/降规模提示：在 Apple Silicon 或 CPU 上运行作业 1  \n",
    "使用助教提供的参考代码，我们可以在一台配备 36 GB 内存的 Apple M3 Max 芯片上，在 **Metal GPU（MPS）** 模式下不到 5 分钟内训练出一个能够生成相对流畅文本的语言模型，用 CPU 训练则大约需要 30 分钟。  \n",
    "如果这些术语对你来说比较陌生，不必担心！只要你的笔记本电脑比较新、实现正确且高效，你就能训练出一个小型语言模型，生成简单儿童故事且流畅度不错。  \n",
    "作业后面会介绍如果你是在 CPU 或 MPS 上运行，需要做哪些调整。  \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
